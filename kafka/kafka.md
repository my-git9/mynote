# 入门

## 简介

### 消息引擎系统

Apache Kafka 是一款开源的消息引擎系统(消息队列)。消息引擎是一组规范，企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的一步式数据传递。通俗来讲，就是系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息。

消息引擎系统要设定具体的传输协议，即我用什么方法把消息传递出去，常见的方法有2种：**点对点模型；发布/订阅模型**。Kafka同时支持这两种消息引擎模型。

- **点对点模型**：也叫消息队列模型。如果拿上面那个“民间版”的定义来说，那么系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。
- **发布/订阅模型**：有一个主题（Topic）的概念，可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布 / 订阅模型。

系统A不能之间发送消息给系统B，中间还要隔一个消息引擎呢，是为了"削峰填谷"，即缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，下游系统可能会直接被压垮导致全链路服务“雪崩”。

### 分布式流处理平台

Apache Kafka 是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）。

Kafka 在设计之初就旨在提供三个方面的特性：

- 提供一套 API 实现生产者和消费者；

- 降低网络传输和磁盘存储开销；

- 实现高伸缩性架构。

**Kafka 社区于 0.10.0.0 版本正式推出了流处理组件 Kafka Streams**，也正是从这个版本开始，Kafka 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。今天 Apache Kafka 是和 Apache Storm、Apache Spark 和 Apache Flink 同等级的实时流处理平台。

作为流处理平台，Kafka 与其他主流大数据流式计算框架相比，优势：

**第一点是更容易实现端到端的正确性（Correctness）**：流处理要最终替代批处理需要具备两点核心优势：要实现正确性和提供能够推导时间的工具。实现正确性是流处理能够匹敌批处理的基石。

因为当这些框架与外部消息引擎系统结合使用时，它们无法影响到外部系统的处理语义，所以如果你搭建了一套环境使得 Spark 或 Flink 从 Kafka 读取消息之后进行有状态的数据计算，最后再写回 Kafka，那么你只能保证在 Spark 或 Flink 内部，这条消息对于状态的影响只有一次。但是计算结果有可能多次写入到 Kafka，因为它们不能控制 Kafka 的语义处理。相反地，Kafka 则不是这样，因为所有的数据流转和计算都在 Kafka 内部完成，故 Kafka 可以实现端到端的精确一次处理语义。

**可能助力 Kafka 胜出的第二点是它自己对于流式计算的定位。**官网上明确标识 Kafka Streams 是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统。这就是说，你不能期望着 Kafka 提供类似于集群调度、弹性部署等开箱即用的运维特性，你需要自己选择适合的工具或系统来帮助 Kafka 流处理应用实现这些功能。

这的确是一个“双刃剑”的设计，也是 Kafka 社区“剑走偏锋”不正面 PK 其他流计算框架的特意考量。大型公司的流处理平台一定是大规模部署的，因此具备集群调度功能以及灵活的部署方案是不可或缺的要素。但毕竟这世界上还存在着很多中小企业，它们的流处理数据量并不巨大，逻辑也并不复杂，部署几台或十几台机器足以应付。

Apache Kafka 从一个优秀的消息引擎系统起家，逐渐演变成现在分布式的流处理平台。

我们在评估流处理平台的时候，框架本身的性能、所提供操作算子（Operator）的丰富程度固然是重要的评判指标，但框架与上下游交互的能力也是非常重要的。能够与之进行数据传输的外部系统越多，围绕它打造的生态圈就越牢固，因而也就有更多的人愿意去使用它，从而形成正向反馈，不断地促进该生态圈的发展。就 Kafka 而言，**Kafka Connect **通过一个个具体的连接器（Connector），串联起上下游的外部系统。

整个 Kafka 生态圈如下图所示。值得注意的是，这张图中的外部系统只是 Kafka Connect 组件支持的一部分而已。目前还有一个可喜的趋势是使用 Kafka Connect 组件的用户越来越多，相信在未来会有越来越多的人开发自己的连接器。

![image-20221117171659517](https://tva1.sinaimg.cn/large/008vxvgGgy1h888tjkaghj30zk0i2wfz.jpg)

## kafka术语

### 术语

**消息**：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。

**主题**：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。

**分区**：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。类似 MongoDB 和 Elasticsearch 中的 Sharding、HBase 中的 Region

**消息位移**：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。

**日志段**：kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的**顺序 I/O 写操作**，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

**副本**：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。

**Broker**：Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。

**生产者**：Producer。向主题发布新消息的应用程序。

**消费者**：Consumer。从主题订阅新消息的应用程序。

**消费者位移**：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。

**消费者组**：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。

**重平衡**：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

![image-20221117143738861](https://tva1.sinaimg.cn/large/008vxvgGgy1h8847sulw3j311i0h4q51.jpg)

串联起 Kafka 的三层消息架构：

- 第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。

- 第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。

- 第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。

- 最后，客户端程序只能与分区的领导者副本进行交互。

## kafka发行版

### Apache Kafka

自 Kafka 开源伊始，它便在 Apache 基金会孵化并最终毕业成为顶级项目，它也被称为社区版 Kafka。

Apache Kafka 的劣势在于它仅仅提供最最基础的组件，特别是对于前面提到的 Kafka Connect 而言，社区版 Kafka 只提供一种连接器，即读写磁盘文件的连接器，而没有与其他外部系统交互的连接器，在实际使用过程中需要自行编写代码实现，这是它的一个劣势。

另外 Apache Kafka 没有提供任何监控框架或工具。显然在线上环境不加监控肯定是不可行的，你必然需要借助第三方的监控框架实现对 Kafka 的监控。好消息是目前有一些开源的监控框架可以帮助用于监控 Kafka（比如 Kafka manager）。

### Confluent Kafka

Confluent Kafka 目前分为免费版和企业版两种。前者和 Apache Kafka 非常相像，除了常规的组件之外，免费版还包含**Schema 注册中心和 REST proxy **两大功能。前者是帮助你集中管理 Kafka 消息格式以实现数据前向 / 后向兼容；后者用开放 HTTP 接口的方式允许你通过网络访问 Kafka 的各种功能，这两个都是 Apache Kafka 所没有的。

除此之外，免费版包含了更多的连接器。至于企业版，它提供的功能就更多了，最有用的当属跨数据中心备份和集群监控两大功能了。

### CDH/HDP Kafka

Cloudera 提供的 CDH 和 Hortonworks 提供的 HDP 是非常著名的大数据平台，里面集成了目前主流的大数据框架，能够帮助用户实现从分布式存储、集群调度、流处理到机器学习、实时数据库等全方位的数据处理。

这些大数据平台天然集成了 Apache Kafka，通过便捷化的界面操作将 Kafka 的安装、运维、管理、监控全部统一在控制台中。所有的操作都可以在前端 UI 界面上完成，而不必去执行复杂的 Kafka 命令。另外这些平台提供的监控界面也非常友好，通常不需要进行任何配置就能有效地监控 Kafka。

### 总结

- Apache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。

- Confluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。

- CDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。

## kafka 版本号

### 版本号说明

我们在官网上下载 Kafka 时，会看到这样的版本：

![image-20221117173918718](https://tva1.sinaimg.cn/large/008vxvgGgy1h889grhp7sj30ss05kdga.jpg)

前面的版本号是编译 Kafka 源代码的 Scala 编译器版本，Kafka 服务器端的代码完全由 Scala 语言编写。

对于 kafka-2.12-3.3.1 的提法，真正的 Kafka 版本号实际上是 3.3.1。前面的3是大版本号，即 Major Version；中间的 3 表示小版本号或次版本号，即 Minor Version；最后的 1 表示修订版本号，也就是 Patch 号。

Kafka 社区在发布 1.0.0 版本后，宣布 Kafka 版本命名规则正式从 4 位演进到 3 位，比如 0.11.0.0 版本就是 4 位版本号。

### 版本号演进

[Apache Kafka](https://kafka.apache.org/downloads)

0.7 版本：只提供了最基础的消息队列功能

0.8版本：引入副本机制，至此Kafka成为了一个真正意义上完备的分布式高可用消息队列解决方案。

0.9.0.0版本：增加了基础的安全认证/权限功能；使用Java重写了新版本消费者API；引入了Kafka Connect组件

0.10.0.0版本: 引入了Kafka Streams，正式升级为分布式流处理平台。

0.11.0.0版本：提供了幂等性Producer API以及事物API；对Kafka消息格式做了重构。

1.0、2.0和3.0版本：主要是Kafka Streams的各种改进。

# 基本使用













